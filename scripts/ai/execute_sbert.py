import json
import re
import random  # Importar random para selecionar respostas aleatÃ³rias
import torch
from sentence_transformers import SentenceTransformer, util

# === CONFIGURAÃ‡Ã•ES ===
SIMILARITY_THRESHOLD = 0.4  # ajuste conforme necessÃ¡rio
DEBUG = False               # mude para True se quiser prints detalhados

# === NORMALIZAÃ‡ÃƒO DE TEXTO ===
def normalize(text):
    """Normaliza o texto removendo pontuaÃ§Ã£o e convertendo para minÃºsculas."""
    return re.sub(r"[^\w\s]", "", text.lower().strip())

# === 1. Carregar modelo SBERT ===
print("ğŸ”§ Carregando modelo SBERT multilÃ­ngue...")
try:
    model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
    print("âœ… Modelo carregado com sucesso!\n")
except Exception as e:
    print(f"âŒ Erro ao carregar o modelo SBERT: {e}")
    exit()

# === 2. Carregar dataset com memÃ³ria da Vendy ===
try:
    with open('C:/Users/NOTE/Desktop/Vendy/data/dataset_vendy.json', 'r', encoding='utf-8') as f:
        vendy_memory = json.load(f)

    if not isinstance(vendy_memory, list):
        raise ValueError("âŒ O dataset deve ser uma lista de entradas.")

    print(f"ğŸ“‚ {len(vendy_memory)} entradas carregadas.")
except Exception as e:
    print(f"âŒ Erro ao carregar o dataset: {e}")
    exit()

# === 3. Carregar respostas para perguntas repetidas ===
try:
    with open('C:/Users/NOTE/Desktop/Vendy/data/repeated_responses.json', 'r', encoding='utf-8') as f:
        repeated_responses = json.load(f)
except Exception as e:
    print(f"âŒ Erro ao carregar o arquivo de respostas repetidas: {e}")
    exit()

# === 4. PrÃ©-computar embeddings das perguntas ===
print("ğŸ§  Calculando embeddings...")
for entry in vendy_memory:
    if "input" in entry:
        norm_input = normalize(entry["input"])
        entry["embedding"] = model.encode(norm_input, convert_to_tensor=True)
print("âœ… Embeddings prontos.\n")

# === 5. GeraÃ§Ã£o de resposta por similaridade ===
# Armazenar perguntas feitas pelo jogador
asked_questions = set()

def generate_response(player_input):
    """Gera uma resposta com base na similaridade do input do jogador."""
    norm_input = normalize(player_input)

    # Verifica se a pergunta jÃ¡ foi feita
    if norm_input in asked_questions:
        # Seleciona uma resposta aleatÃ³ria da lista de respostas
        if norm_input in repeated_responses:
            return random.choice(repeated_responses[norm_input])

    # Adiciona a pergunta ao conjunto de perguntas feitas
    asked_questions.add(norm_input)

    player_embedding = model.encode(norm_input, convert_to_tensor=True)

    best_score = -1
    best_output = "Desculpe, nÃ£o consegui entender o suficiente para responder..."
    best_match = ""

    for entry in vendy_memory:
        if "embedding" in entry and "output" in entry:
            similarity = util.pytorch_cos_sim(player_embedding, entry["embedding"]).item()
            if DEBUG:
                print(f"ğŸ” Comparando com: \"{entry['input']}\" â†’ Similaridade: {similarity:.4f}")

            if similarity > best_score:
                best_score = similarity
                best_output = entry["output"]
                best_match = entry["input"]

    if best_score < SIMILARITY_THRESHOLD:
        return "Desculpe... meus dados nÃ£o sÃ£o suficientes para responder isso com certeza."

    if DEBUG:
        print(f"\nâœ… Melhor correspondÃªncia: \"{best_match}\" (score: {best_score:.4f})")
        print(f"ğŸ—¨ï¸ Resposta: \"{best_output}\"\n")

    return best_output

# === 6. Loop interativo ===
print("ğŸŸ¢ Vendy (SBERT) inicializada. Pergunte algo (ou digite 'sair'):\n")

while True:
    player_input = input("Detetive: ").strip()
    if player_input.lower() == "sair":
        print("Vendy: Encerrando interface... AtÃ© logo.")
        break

    response = generate_response(player_input)
    print(f"Vendy: {response}\n")
